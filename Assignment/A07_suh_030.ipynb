{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFZRpLpK02pB"
   },
   "source": [
    "### Name: Suhas Sadashiv Kolekar\n",
    "\n",
    "### PRN :230940128030"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deSnZmVy02pF"
   },
   "source": [
    "\n",
    "# Deep Neural Networks\n",
    "\n",
    "## Assignment: 7\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "rt0pfyeA02pK"
   },
   "outputs": [],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections.abc import Callable\n",
    "from typing import Literal\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "__T9cczP02pL"
   },
   "outputs": [],
   "source": [
    "###----------------\n",
    "### Some parameters\n",
    "###----------------\n",
    "\n",
    "inpDir = '../input'\n",
    "outDir = '../output'\n",
    "modelDir = '../model'\n",
    "subDir = '../subDir'\n",
    "\n",
    "RANDOM_STATE = 24 # REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible  results\n",
    "\n",
    "EPOCHS = 10 # number of epochs\n",
    "ALPHA = 0.01 # learning rate\n",
    "NUM_SAMPLES = 1280 # How many samples we want to generate \n",
    "NOISE = 0.2 # Noise to be introduced in the data\n",
    "TEST_SIZE = 0.2\n",
    "TRAIN_SIZE = 14496 # Fix size of train set so that we have batches of same size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 8),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "CMAP = 'coolwarm' # plt.cm.Spectral\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "##### - Weather History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115395"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('shakespeare.txt','rb').read().decode(encoding='utf-8')\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i,u in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
       "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = np.array(vocab)\n",
    "\n",
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115395,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the charcter in the shakespear dataset into integers.\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ...,  8,  0,  0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 'F')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char[47], idx2char[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the input data integers into tensors\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(text_as_int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11043"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the given dataset into batches\n",
    "\n",
    "seq_length = 100\n",
    "\n",
    "example_per_epoch = len(text) // ( seq_length + 1 )\n",
    "\n",
    "example_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 | F\n",
      "47 | i\n",
      "56 | r\n",
      "57 | s\n",
      "58 | t\n",
      "1 |  \n",
      "15 | C\n",
      "47 | i\n",
      "58 | t\n",
      "47 | i\n"
     ]
    }
   ],
   "source": [
    "# we have applied .numpy() method, because values inside the dataset are in tensor form.\n",
    "\n",
    "for i in dataset.take(10):\n",
    "    print (i.numpy(), '|', idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int64)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "\n",
      "\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int64)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences = dataset.batch(seq_length + 1, drop_remainder=True) # converted into batch\n",
    "\n",
    "for item in sequences.take(2):\n",
    "    \n",
    "    print(item)\n",
    "    \n",
    "    print(repr(''.join(idx2char[item.numpy()]))) # take index values and convert to char\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_split_X_y(seq): # bring in sequence of length 101\n",
    "    \n",
    "    input_text = seq[:-1] # input in first 100 characters\n",
    "    \n",
    "    output_text =  seq[1:] # output is the last 100 characters\n",
    "    \n",
    "    return input_text, output_text\n",
    "\n",
    "dataset = sequences.map(fn_split_X_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
      "'re all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for X,y in dataset.take(2):\n",
    "    print(repr(''.join(idx2char[X.numpy()]))) # X data\n",
    "    print(repr(''.join(idx2char[y.numpy()]))) # y data\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000 \n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "'''\n",
    "    1. Building model using tensorflow.keras\n",
    "    2. we will keep a first hidden layer as embedding layer (to reduce the input dimension)\n",
    "    3. 2nd hidden layer is GRU unit    \n",
    "'''\n",
    "\n",
    "\n",
    "def build_model(vocab_size, \n",
    "                embedding_dim, \n",
    "                rnn_units,\n",
    "               batch_size = BATCH_SIZE):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        # Embedding layer will reduce the vocabulary size to 256\n",
    "        \n",
    "        tf.keras.layers.Embedding(vocab_size, \n",
    "                                  embedding_dim, \n",
    "                                  batch_input_shape = [batch_size, None]),\n",
    "        \n",
    "        # GRU units are used in sequence prediction probelms.\n",
    "        \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                           return_sequences=True,\n",
    "                            stateful=True,\n",
    "                           recurrent_initializer='orthogonal'),\n",
    "        \n",
    "        # RNN layers are\n",
    "        \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = build_model(vocab_size, \n",
    "                    embedding_dim,\n",
    "                   rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021569 (15.34 MB)\n",
      "Trainable params: 4021569 (15.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in dataset.take(2):\n",
    "    \n",
    "    y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100, 65])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                                name='Adam')\n",
    "\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "             loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "chktPtPath = os.path.join(modelDir,subDir)\n",
    "\n",
    "chktPtPrefix = os.path.join(chktPtPath, 'chkpt_{epoch}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chktPtPrefix,\n",
    "                                                        save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 174s 995ms/step - loss: 2.6966\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 172s 992ms/step - loss: 1.9902\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 172s 989ms/step - loss: 1.7220\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 170s 984ms/step - loss: 1.5661\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 171s 985ms/step - loss: 1.4742\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 170s 980ms/step - loss: 1.4120\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 170s 979ms/step - loss: 1.3657\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 170s 979ms/step - loss: 1.3276\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 170s 980ms/step - loss: 1.2921\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 170s 982ms/step - loss: 1.2603\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(dataset, \n",
    "                 epochs=EPOCHS, \n",
    "                 callbacks=[checkpoint_callback]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/../subDir/chkpt_10'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(chktPtPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (1, None, 256)            16640     \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021569 (15.34 MB)\n",
      "Trainable params: 4021569 (15.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size,\n",
    "                   embedding_dim,\n",
    "                   rnn_units,\n",
    "                   batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(chktPtPath))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (1, None, 256)            16640     \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021569 (15.34 MB)\n",
      "Trainable params: 4021569 (15.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(tf.TensorShape([1,None],))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(model, start_string):\n",
    "    \n",
    "    num_generate = 1000\n",
    "    \n",
    "    input_eval = [char2idx[c] for c in start_string]\n",
    "    \n",
    "    print(f'Input: {start_string} | {input_eval}')\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range (num_generate):\n",
    "        \n",
    "        prediction = model(input_eval)\n",
    "        \n",
    "        prediction = tf.squeeze(prediction, 0)\n",
    "        \n",
    "        prediction_td = tf.random.categorical(prediction, \n",
    "                                              num_samples=1)[-1,0].numpy()\n",
    "          \n",
    "        input_eval = tf.expand_dims([prediction_td],0)\n",
    "        \n",
    "        text_generated.extend(idx2char[prediction_td])\n",
    "        \n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ROMEO: | [30, 27, 25, 17, 27, 10]\n",
      "ROMEO:\n",
      "Now thus they drgue distrets me from the love,--\n",
      "My fault were to this paper, treibor person,\n",
      "To pracity hath another slain,--we may burns to him:\n",
      "And old-leadings, as I came thy brother's bonish'd,\n",
      "Were once a Chrept ball comes you I expy this thing;\n",
      "Lord, which may but still they so, so was a\n",
      "sweet sir, sba by through the surphrow thou art madam.\n",
      "\n",
      "CLARENCE:\n",
      "Bethis gave my true. first I may bark,\n",
      "My face that love's great is; we shall say it\n",
      "is this parand will in this vargian's blow,\n",
      "Is well as hided that hath a plays are;\n",
      "What words thine and that death:\n",
      "But come against so I offen alm,\n",
      "Let, what the watery of our instructions since my heart you shall.\n",
      "\n",
      "POMPEY:\n",
      "I desire they, ar sorrew at mine,\n",
      "I make him speak, and there, limes that assegurs a horse and partly\n",
      "Floed to the news, in bratester and 'T:\n",
      "So, by some destin themselves:\n",
      "Might weep'd upon, and so, I wish\n",
      "'Shall she living lifening.\n",
      "\n",
      "TRANIO:\n",
      "Dapility, that kill'd his oaths i' touch the wits;\n",
      "Would ift in condutted soul\n",
      "Ful\n"
     ]
    }
   ],
   "source": [
    "print(gen_text(model, start_string=u'ROMEO:'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "S05a_one_hidden_layer_with_tanh_wip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
